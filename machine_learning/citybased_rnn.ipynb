{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "citybased_rnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "BFLtqc6hXszW",
        "colab_type": "code",
        "outputId": "d3ff6e60-ec95-4e5e-f79e-c398db8e8f53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Setup of libraries, mounting the Google Drive etc.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('gdrive/My Drive/Colab Notebooks')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lHDRiK7LYw2s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read the dataset from `.pkl` file\n"
      ]
    },
    {
      "metadata": {
        "id": "rxQz-vmJYEGC",
        "colab_type": "code",
        "outputId": "6d171034-bf3d-4589-abb8-84101582aa2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle('cabspotting.pkl')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>occupied</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user</th>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">abboip</th>\n",
              "      <th>2008-05-17 14:12:10</th>\n",
              "      <td>37.75153</td>\n",
              "      <td>-122.39447</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-05-17 14:13:34</th>\n",
              "      <td>37.75149</td>\n",
              "      <td>-122.39447</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-05-17 14:14:34</th>\n",
              "      <td>37.75149</td>\n",
              "      <td>-122.39447</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-05-17 14:15:35</th>\n",
              "      <td>37.75149</td>\n",
              "      <td>-122.39446</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-05-17 14:41:43</th>\n",
              "      <td>37.75144</td>\n",
              "      <td>-122.39449</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            latitude  longitude  occupied\n",
              "user   time                                              \n",
              "abboip 2008-05-17 14:12:10  37.75153 -122.39447         0\n",
              "       2008-05-17 14:13:34  37.75149 -122.39447         0\n",
              "       2008-05-17 14:14:34  37.75149 -122.39447         0\n",
              "       2008-05-17 14:15:35  37.75149 -122.39446         0\n",
              "       2008-05-17 14:41:43  37.75144 -122.39449         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "SRCEhqT6ZLYO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convert the dataset to a mapping of users to the strings of their movements"
      ]
    },
    {
      "metadata": {
        "id": "dhYusASNGJzh",
        "colab_type": "code",
        "outputId": "f6f89e00-df1f-4a02-ca4b-f6fb65615be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "df['rebased_time'] = df['time'] - df['time'].min()\n",
        "df['rebased_time'] = df['rebased_time'].dt.total_seconds()\n",
        "\n",
        "df = df[['user', 'rebased_time', 'longitude', 'latitude']]\n",
        "\n",
        "def extract_sequence(df):\n",
        "    df.drop('user', axis=1, inplace=True)\n",
        "    df.sort_values(by='rebased_time', inplace=True)\n",
        "    return df.values\n",
        "\n",
        "df = df.groupby('user').apply(extract_sequence)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user\n",
              "abboip      [[15126.000000000002, -122.39447, 37.751529999...\n",
              "abcoij      [[47486.0, -122.41466000000001, 37.80346], [47...\n",
              "abdremlu    [[11949.0, -122.39093000000001, 37.75521], [12...\n",
              "abgibo      [[16.0, -122.4374, 37.7733], [61.0000000000000...\n",
              "abjoolaw    [[13856.0, -122.39747, 37.75159], [13916.0, -1...\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "G7jbyag-Ztfr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Concatenate all user strings of data to one complete string of all"
      ]
    },
    {
      "metadata": {
        "id": "M8CBIqVHG8BQ",
        "colab_type": "code",
        "outputId": "0dc04b66-3521-4747-e62a-9b38626839f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "def to_single_sequence(series):\n",
        "    data = None\n",
        "    for _, item in series.iteritems():\n",
        "        if data is None:\n",
        "            data = item\n",
        "        else:\n",
        "            data = np.concatenate((data, item), axis=0)\n",
        "    \n",
        "    return data\n",
        "\n",
        "data = to_single_sequence(df)\n",
        "del df\n",
        "\n",
        "print(data.shape)\n",
        "print()\n",
        "print(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11219955, 3)\n",
            "\n",
            "[[ 1.5126000e+04 -1.2239447e+02  3.7751530e+01]\n",
            " [ 1.5210000e+04 -1.2239447e+02  3.7751490e+01]\n",
            " [ 1.5270000e+04 -1.2239447e+02  3.7751490e+01]\n",
            " ...\n",
            " [ 2.0172080e+06 -1.2244239e+02  3.7756860e+01]\n",
            " [ 2.0172640e+06 -1.2244215e+02  3.7760470e+01]\n",
            " [ 2.0173250e+06 -1.2243687e+02  3.7760750e+01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "noA-JMxmZ9k0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Standardisation\n",
        "All three features in the data are scaled to have a `mean = 0` and a `standard deviation = 1`."
      ]
    },
    {
      "metadata": {
        "id": "4eXEW0wkH2_W",
        "colab_type": "code",
        "outputId": "72c637f6-5c2c-400f-869c-a38f166b4fa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(data)\n",
        "\n",
        "data = scaler.transform(data)\n",
        "\n",
        "print('Means: %f %f %f' % (scaler.mean_[0], scaler.mean_[1], scaler.mean_[2]))\n",
        "print('Standard deviations: %f %f %f' % (scaler.var_[0], scaler.var_[1], scaler.var_[2]))\n",
        "print()\n",
        "print(data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Means: 1017983.546543 -122.412432 37.763601\n",
            "Standard deviations: 346406383099.499146 0.001280 0.002901\n",
            "\n",
            "[[-1.70390864  0.50197561 -0.22410877]\n",
            " [-1.70376591  0.50197561 -0.22485143]\n",
            " [-1.70366397  0.50197561 -0.22485143]\n",
            " ...\n",
            " [ 1.69773582 -0.83724035 -0.12514886]\n",
            " [ 1.69783096 -0.83053309 -0.05812348]\n",
            " [ 1.69793461 -0.6829734  -0.05292484]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tgh9Jnhbvo7a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convert the data to 32-bit integers\n",
        "This is to correct an error I got earlier. Apparently the GRU layers can't handle 64-bit integers (doubles) as input."
      ]
    },
    {
      "metadata": {
        "id": "WY07YNcWv2RS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1d8b452-e766-4e58-ae24-b27aee1422ba"
      },
      "cell_type": "code",
      "source": [
        "print('Before: ', data.dtype)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before:  float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l9yt0kQWwH-h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = data.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_DHJn_9waE1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56ea20c9-e3bd-4562-9b0b-38b89a6d60b1"
      },
      "cell_type": "code",
      "source": [
        "print('After: ', data.dtype)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After:  float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gl3WTuKNckiI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Split the data into a set for training and one for testing\n",
        "The split happens along the complete string of all concatenated user movement data."
      ]
    },
    {
      "metadata": {
        "id": "yJt_A5A9IJT8",
        "colab_type": "code",
        "outputId": "25f4b5db-b8e2-45e4-9436-460909ce216d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "TRAIN_TEST_SPLIT = 0.8\n",
        "\n",
        "n_train = int(np.floor(TRAIN_TEST_SPLIT * data.shape[0]))\n",
        "\n",
        "train_data = data[0:n_train]\n",
        "test_data = data[n_train:]\n",
        "\n",
        "train_data.shape, test_data.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8975964, 3), (2243991, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "kisbkHprc6iX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Instantiate TensorFlow Dataset from the data"
      ]
    },
    {
      "metadata": {
        "id": "c6EEcfD5V1_v",
        "colab_type": "code",
        "outputId": "4f91babb-8b4b-4bca-df21-1c75c9cc7153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH = 100\n",
        "examples_per_epoch = len(train_data) // SEQ_LENGTH\n",
        "\n",
        "# Create training examples / targets\n",
        "dataset = tf.data.Dataset.from_tensor_slices(train_data)\n",
        "\n",
        "for rec in dataset.take(5):\n",
        "    print(rec.numpy())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.7039087   0.5019756  -0.22410877]\n",
            "[-1.7037659   0.5019756  -0.22485143]\n",
            "[-1.703664    0.5019756  -0.22485143]\n",
            "[-1.7035604   0.5022551  -0.22485143]\n",
            "[-1.7008963   0.5014167  -0.22577976]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8aVXQAb4dnEq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Split into sequences"
      ]
    },
    {
      "metadata": {
        "id": "kwQwKc2rW2C5",
        "colab_type": "code",
        "outputId": "da32969d-0e58-499e-ea24-94dd00b8dbd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "sequences = dataset.batch(SEQ_LENGTH + 1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(5):\n",
        "    print(seq.numpy()[0], seq.numpy()[1], seq.numpy()[2],' ...')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.7039087   0.5019756  -0.22410877] [-1.7037659   0.5019756  -0.22485143] [-1.703664    0.5019756  -0.22485143]  ...\n",
            "[-1.6920493  0.661273  -1.6295995] [-1.6919813  0.6120864 -1.3839635] [-1.691898   0.5290841 -1.1390702]  ...\n",
            "[-1.6829762  -0.03460507 -0.27702355] [-1.6828743  -0.0415918  -0.23710538] [-1.6827741  -0.05277057 -0.20127188]  ...\n",
            "[-1.6731405  0.4949889  0.2482252] [-1.6730623   0.49331206  0.24673986] [-1.6730607   0.49359155  0.24673986]  ...\n",
            "[-1.6638908  -0.6522318   0.48513484] [-1.6638585 -0.6519523  0.4816072] [-1.6637549 -0.6418914  0.451715 ]  ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tJK618v0d23y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make input and output sequences\n",
        "... by dropping the first or the last record respectively."
      ]
    },
    {
      "metadata": {
        "id": "oa4D64QjXui6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "    input_seq = chunk[:-1]\n",
        "    target_seq = chunk[1:]\n",
        "    \n",
        "    return input_seq, target_seq\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MkLfnQMkYJth",
        "colab_type": "code",
        "outputId": "69d2a35f-8c45-4dd5-aba8-0813fd234b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print('Input data: ', input_example.numpy()[0], input_example.numpy()[1], input_example.numpy()[2],' ...')\n",
        "    print('Target data:', target_example.numpy()[0], target_example.numpy()[1], target_example.numpy()[2], ' ...')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  [-1.7039087   0.5019756  -0.22410877] [-1.7037659   0.5019756  -0.22485143] [-1.703664    0.5019756  -0.22485143]  ...\n",
            "Target data: [-1.7037659   0.5019756  -0.22485143] [-1.703664    0.5019756  -0.22485143] [-1.7035604   0.5022551  -0.22485143]  ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4yMKfhXwZlxr",
        "colab_type": "code",
        "outputId": "a098a30d-bc0f-4dcc-b1d1-771eecb88ed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "for i, (input_rec, target_rec) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print('Step {:4d}'.format(i))\n",
        "    print('  input: ', input_rec.numpy())\n",
        "    print('  expected output: ', target_rec.numpy())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input:  [-1.7039087   0.5019756  -0.22410877]\n",
            "  expected output:  [-1.7037659   0.5019756  -0.22485143]\n",
            "Step    1\n",
            "  input:  [-1.7037659   0.5019756  -0.22485143]\n",
            "  expected output:  [-1.703664    0.5019756  -0.22485143]\n",
            "Step    2\n",
            "  input:  [-1.703664    0.5019756  -0.22485143]\n",
            "  expected output:  [-1.7035604   0.5022551  -0.22485143]\n",
            "Step    3\n",
            "  input:  [-1.7035604   0.5022551  -0.22485143]\n",
            "  expected output:  [-1.7008963   0.5014167  -0.22577976]\n",
            "Step    4\n",
            "  input:  [-1.7008963   0.5014167  -0.22577976]\n",
            "  expected output:  [-1.7007756  0.5002988 -0.2244801]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jvh55ttEeW7Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Shuffle and split the dataset into batches"
      ]
    },
    {
      "metadata": {
        "id": "dUZyw_LRaevX",
        "colab_type": "code",
        "outputId": "df93e885-bcdf-4998-e896-3cbdf67f8926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = examples_per_epoch // BATCH_SIZE\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences, \n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead, \n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100, 3), (64, 100, 3)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "vFm92XsBiiGO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Definition of how to build the model\n",
        "The first cell selects the type of GRU layer to use depending on wether the algorithm is run on a CPU or GPU."
      ]
    },
    {
      "metadata": {
        "id": "AYP7sev5a-tq",
        "colab_type": "code",
        "outputId": "e4f696a1-619f-4354-8c6c-1be460f03c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "if tf.test.is_gpu_available():\n",
        "    my_gru = tf.keras.layers.CuDNNGRU\n",
        "    print('Selected GRU layer for GPU')\n",
        "else:\n",
        "    import functools\n",
        "    my_gru = functools.partial(\n",
        "        tf.keras.layers.GRU, recurrent_activation='sigmoid')\n",
        "    print('Selected GRU layer for CPU')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected GRU layer for GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ywCXItWdbO1L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model(internal_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        my_gru(internal_units, return_sequences=True, recurrent_initializer='glorot_uniform', stateful=True, batch_input_shape=[batch_size, None, 3]),\n",
        "        tf.keras.layers.Dense(3)\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16DqcUiUi2uN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build the model"
      ]
    },
    {
      "metadata": {
        "id": "GE11g2X-efxh",
        "colab_type": "code",
        "outputId": "c3b57e94-80cf-4dc2-c377-4312ffa45463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "INTERNAL_UNITS = 1024\n",
        "\n",
        "model = build_model(internal_units=INTERNAL_UNITS, batch_size=BATCH_SIZE)\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnngru (CuDNNGRU)         (64, None, 1024)          3161088   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 3)             3075      \n",
            "=================================================================\n",
            "Total params: 3,164,163\n",
            "Trainable params: 3,164,163\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JP5X850FjANF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test the model's output (before training)"
      ]
    },
    {
      "metadata": {
        "id": "WdqsUva28s6k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a392e1ae-2486-4cf7-fcca-1cbc66dd1992"
      },
      "cell_type": "code",
      "source": [
        "model.input"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DeferredTensor 'cu_dnngru_input' shape=(64, ?, 3) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "N4QAgyB1ewT0",
        "colab_type": "code",
        "outputId": "44acf133-3079-4d5b-9113-ad7cf416fd11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1): \n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, n_features)\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 3) # (batch_size, sequence_length, n_features)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8QET49P8xCcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "72a0c127-749b-4246-f0b2-c0d54c9a7822"
      },
      "cell_type": "code",
      "source": [
        "scaler.inverse_transform(example_batch_predictions[0].numpy()[:5])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.01066512e+06, -1.22413895e+02,  3.77626343e+01],\n",
              "       [ 1.01131806e+06, -1.22413834e+02,  3.77628174e+01],\n",
              "       [ 1.01227206e+06, -1.22413780e+02,  3.77629433e+01],\n",
              "       [ 1.01372819e+06, -1.22413666e+02,  3.77630997e+01],\n",
              "       [ 1.01519075e+06, -1.22413635e+02,  3.77631416e+01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "n1gfHCGwykZp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c094a81-a998-4718-93c4-69e7563a65ea"
      },
      "cell_type": "code",
      "source": [
        "print('Loss: ', tf.keras.losses.mean_absolute_error(target_example_batch, example_batch_predictions).numpy().mean())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.6429231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dkkKIrBR2qdl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "H8Ai1h_t2p8h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "              loss=tf.keras.losses.mean_absolute_error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "svDi3JIb2y4-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './onegru_training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}_{loss}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
        "                                                         save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uAlrq5LY3niS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1629
        },
        "outputId": "91c63d67-5855-4483-a202-8bdb33baaa02"
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model.fit(dataset.repeat(),\n",
        "                    epochs=EPOCHS,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    val\n",
        "                    callbacks=[checkpoint_callback])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1402/1402 [==============================] - 190s 135ms/step - loss: 0.0426\n",
            "Epoch 2/30\n",
            "1402/1402 [==============================] - 188s 134ms/step - loss: 0.0344\n",
            "Epoch 3/30\n",
            "1402/1402 [==============================] - 189s 135ms/step - loss: 0.0321\n",
            "Epoch 4/30\n",
            "1402/1402 [==============================] - 189s 134ms/step - loss: 0.0308\n",
            "Epoch 5/30\n",
            "1402/1402 [==============================] - 188s 134ms/step - loss: 0.0301\n",
            "Epoch 6/30\n",
            "1402/1402 [==============================] - 189s 135ms/step - loss: 0.0297\n",
            "Epoch 7/30\n",
            "1402/1402 [==============================] - 188s 134ms/step - loss: 0.0292\n",
            "Epoch 8/30\n",
            "1402/1402 [==============================] - 189s 135ms/step - loss: 0.0289\n",
            "Epoch 9/30\n",
            "1402/1402 [==============================] - 190s 135ms/step - loss: 0.0286\n",
            "Epoch 10/30\n",
            " 782/1402 [===============>..............] - ETA: 1:23 - loss: 0.0286"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-e1f9834a4429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     callbacks=[checkpoint_callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1612\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1615\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m       return training_distributed.fit_loop(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, class_weight, val_inputs, val_targets, val_sample_weights, batch_size, epochs, verbose, callbacks, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    703\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m           \u001b[0mdo_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m           batch_size=batch_size)\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36miterator_fit_loop\u001b[0;34m(model, inputs, class_weight, steps_per_epoch, epoch_logs, val_inputs, val_targets, val_sample_weights, epochs, verbose, callbacks, validation_steps, do_validation, batch_size)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# Train model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     outs, loss, loss_metrics, masks = _process_single_batch(\n\u001b[0;32m--> 251\u001b[0;31m         model, x, y, sample_weights=sample_weights, training=True)\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, sample_weights, training)\u001b[0m\n\u001b[1;32m    509\u001b[0m           \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m           training=training)\n\u001b[0m\u001b[1;32m    512\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         raise ValueError('The model cannot be run '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[0;34m(model, inputs, targets, sample_weights, training)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         output_loss = weighted_masked_fn(\n\u001b[0;32m--> 113\u001b[0;31m             targets[i], outs[i], weights, mask=mask)\n\u001b[0m\u001b[1;32m    114\u001b[0m       \u001b[0;31m# If the number of outputs is 1 then we don't append the loss metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m       \u001b[0;31m# associated with each model output. When there are multiple outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \"\"\"\n\u001b[1;32m    597\u001b[0m     \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m       \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     47\u001b[0m            'keras.losses.MAE')\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   8329\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   8330\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sub\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8331\u001b[0;31m         _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[1;32m   8332\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8333\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}